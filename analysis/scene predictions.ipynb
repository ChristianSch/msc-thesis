{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "import skml\n",
    "from skml.problem_transformation import ProbabilisticClassifierChain\n",
    "from skml.datasets import sample_down_label_space\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.base import clone\n",
    "from sklearn.externals import joblib\n",
    "import arff\n",
    "import os\n",
    "import time\n",
    "\n",
    "from lib.experimental_framework import load_from_arff\n",
    "random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = load_from_arff('../data/scene/scene-train.arff', labelcount=6)\n",
    "data_test = load_from_arff('../data/scene/scene-test.arff', labelcount=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = data_train\n",
    "X_test, Y_test = data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.A\n",
    "Y_train = Y_train.A\n",
    "X_test = X_test.A\n",
    "Y_test = Y_test.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncertain_hamming_loss(y, y_pred, omega=1.0):\n",
    "    N, L = y_pred.shape\n",
    "    cumsum = 0\n",
    "    \n",
    "    # place '?' if not already done\n",
    "    np.place(y_pred, \n",
    "             mask=np.logical_and(y_pred > 1/3, y_pred < 2/3),\n",
    "             vals=np.nan)\n",
    "    u = np.isnan(y_pred).sum()\n",
    "    hl = ((y_pred>= .5) != y.astype(float)).sum()\n",
    "    print(\"hl\", hl / (N * L))\n",
    "    return (hl + (u * omega)) / (N * L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_test, y_pred, y_pred_pp):\n",
    "    print(\"----------\")\n",
    "\n",
    "    print(\"hamming loss: \")\n",
    "    print(hamming_loss(y_test, y_pred))\n",
    "\n",
    "    print(\"accuracy:\")\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "    print(\"f1 score:\")\n",
    "    print(\"micro\")\n",
    "    print(f1_score(y_test, y_pred, average='micro'))\n",
    "    print(\"macro\")\n",
    "    print(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    print(\"precision:\")\n",
    "    print(\"micro\")\n",
    "    print(precision_score(y_test, y_pred, average='micro'))\n",
    "    print(\"macro\")\n",
    "    print(precision_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    print(\"recall:\")\n",
    "    print(\"micro\")\n",
    "    print(recall_score(y_test, y_pred, average='micro'))\n",
    "    print(\"macro\")\n",
    "    print(recall_score(y_test, y_pred, average='macro'))\n",
    "    \n",
    "    print(\"#--\")\n",
    "    print(\"-> hamming loss:\")\n",
    "    print(hamming_loss(y_test, (y_pred_pp >= .5)))\n",
    "    print(\"-> uncertain hamming loss:\")\n",
    "    print(uncertain_hamming_loss(y_test, y_pred_pp))\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ProbabilisticClassifierChain(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_pred_pp = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    " y_pred_pp = y_pred_pp.reshape(y_pred_pp.shape[0], y_pred_pp.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "hamming loss: \n",
      "0.016583054626532888\n",
      "accuracy:\n",
      "0.9657190635451505\n",
      "f1 score:\n",
      "micro\n",
      "0.0\n",
      "macro\n",
      "0.0\n",
      "precision:\n",
      "micro\n",
      "0.0\n",
      "macro\n",
      "0.0\n",
      "recall:\n",
      "micro\n",
      "0.0\n",
      "macro\n",
      "0.0\n",
      "#--\n",
      "-> hamming loss:\n",
      "0.3435061315496098\n",
      "-> uncertain hamming loss:\n",
      "hl 0.21920289855072464\n",
      "0.48648272017837235\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "evaluate(Y_test, y_pred, y_pred_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.46426968e-04, 2.99448730e-02, 5.28635016e-02, 3.16679093e-01,\n",
       "        2.24009413e-01, 3.10165689e-01],\n",
       "       [1.46012870e-03, 9.31928431e-02, 2.58314587e-01,            nan,\n",
       "        2.94657343e-01,            nan],\n",
       "       [2.25403197e-03, 2.36610684e-01, 1.96784118e-01,            nan,\n",
       "        1.24495300e-01, 3.32401752e-01],\n",
       "       [6.87654789e-05, 9.17625053e-03, 1.03532534e-02, 1.30296731e-01,\n",
       "        9.99417786e-03, 4.29246421e-02],\n",
       "       [7.43127025e-03, 1.39004758e-01, 3.31822014e-01, 7.65316385e-01,\n",
       "        8.32266021e-01,            nan],\n",
       "       [8.85383040e-04, 6.32877726e-02, 1.28559140e-01,            nan,\n",
       "        1.32509427e-01, 2.19657664e-01],\n",
       "       [9.85582628e-04, 2.80592139e-02, 6.04799147e-02,            nan,\n",
       "        1.75416554e-01, 7.29236877e-01],\n",
       "       [1.31515706e-03, 1.04446816e-01, 8.44195354e-02,            nan,\n",
       "                   nan,            nan],\n",
       "       [7.49451245e-04, 4.45986187e-02, 2.12161083e-01, 6.72420961e-01,\n",
       "                   nan, 9.14306398e-01],\n",
       "       [2.23042977e-03, 8.47997245e-02,            nan, 9.01461349e-01,\n",
       "        7.82026693e-01, 6.72378897e-01]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_pp[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
